{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lw_1rBMUpwQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6316b76-a89a-4824-ed79-b4b8c61037db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install torchmetrics\n",
        "!pip install torchsummary"
      ],
      "metadata": {
        "id": "0j286GFXc-Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bertopic\n",
        "!pip uninstall joblib\n",
        "!pip install --upgrade joblib==1.1.0"
      ],
      "metadata": {
        "id": "O2R9Asr33SzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy, pickle, ast\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import os.path as osp\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, classification_report\n",
        "import torch_geometric.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATv2Conv, Linear, to_hetero, to_hetero_with_bases, SAGEConv\n",
        "from torch_geometric.data import HeteroData, InMemoryDataset, download_url\n",
        "from torch_geometric.utils import negative_sampling, to_networkx\n",
        "from torch_geometric.loader import GraphSAINTRandomWalkSampler, HGTLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.nn import Parameter, Embedding\n",
        "from torchmetrics import Accuracy, F1Score\n",
        "from torchsummary import summary\n",
        "from bertopic import BERTopic\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wajGnRzop50l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37_mFGkBqAmg",
        "outputId": "c6848921-0fb6-4269-fe2a-4269cad494de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FOLDER_PATH=\"/content/drive/MyDrive/Knowledge Graphs 2022/\"\n",
        "%cd $FOLDER_PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nhY5JzfqC3a",
        "outputId": "2ecef67c-a148-4050-937f-111f63ba100d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/18wZgIc4f2VuuQ34uv_vRrBAOHvMWSEaq/Knowledge Graphs 2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"KG embedding/tweet_embedding.pickle\", \"rb\") as f:\n",
        "  tweet_embedding_dict = pickle.load(f)\n",
        "\n",
        "print(len(tweet_embedding_dict.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdRMSuemb8_f",
        "outputId": "4e02eeb7-3691-426a-a954-3785623eae6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "923385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_tweets_df = pd.read_csv('data/all_tweets_50_topics.csv', index_col=0)\n",
        "all_tweets_df"
      ],
      "metadata": {
        "id": "pVdkikzqcUQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model = BERTopic.load(\"topic modeling/qanon_tweets_50_topics.model\")\n",
        "topic_ids = list(set(np.arange(50)))\n",
        "idx2topic = {i: topic_ids[i] for i in range(len(topic_ids))}\n",
        "\n",
        "topic_labels = topic_model.custom_labels_[1:]\n",
        "topic_labels"
      ],
      "metadata": {
        "id": "btUPiJzuckyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.visualize_hierarchy(topics=topic_ids, custom_labels=True, color_threshold=1.35)"
      ],
      "metadata": {
        "id": "JB3kRAhhqx0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"KG embedding/idx2tweetId.pickle\", 'rb') as f:\n",
        "  idx2tweetId = pickle.load(f)\n",
        "\n",
        "with open(\"KG embedding/idx2userId.pickle\", 'rb') as f:\n",
        "  idx2userId = pickle.load(f)"
      ],
      "metadata": {
        "id": "ROldnJhxwx4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"KG embedding/dataset/data_dict_node_classification_50_topics.pickle\", \"rb\") as f:\n",
        "  data_dict = pickle.load(f)\n",
        "data = HeteroData(data_dict)\n",
        "data"
      ],
      "metadata": {
        "id": "nOqQBYj_0Ef5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['tweet']"
      ],
      "metadata": {
        "id": "ToP0_KCsgqiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "transform = T.Compose([\n",
        "    T.AddSelfLoops(),\n",
        "    T.ToUndirected(),\n",
        "    T.ToDevice(device),\n",
        "    T.RandomNodeSplit(num_val=0.1, num_test=0.2) ### split\n",
        "])\n",
        "\n",
        "transformed_data = transform(data)\n",
        "transformed_data"
      ],
      "metadata": {
        "id": "rFuseatm7zwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sum(transformed_data['tweet'].val_mask)\n",
        "transformed_data['tweet'].idx"
      ],
      "metadata": {
        "id": "ygSz4IZ8Ew-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = HGTLoader(transformed_data, num_samples=[1024]*4, shuffle=True, batch_size=1024, input_nodes=('tweet', data['tweet'].train_mask), num_workers=2)\n",
        "val_loader = HGTLoader(transformed_data, num_samples=[1024]*4, shuffle=True, batch_size=1024, input_nodes=('tweet', data['tweet'].val_mask), num_workers=2)\n",
        "test_loader = HGTLoader(transformed_data, num_samples=[1024]*4, shuffle=True, batch_size=1024, input_nodes=('tweet', data['tweet'].test_mask), num_workers=2)\n",
        "sampled_data = next(iter(train_loader))\n",
        "print(sampled_data)"
      ],
      "metadata": {
        "id": "q_dAGdHl8Pti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATv2Conv((-1, -1), hidden_channels*2, add_self_loops=False)\n",
        "        # self.lin1 = Linear(-1, hidden_channels*2)\n",
        "        self.conv2 = GATv2Conv((-1, -1), hidden_channels, add_self_loops=False)\n",
        "        # self.lin2 = Linear(-1, hidden_channels)\n",
        "        # self.conv3 = GATv2Conv((-1, -1), hidden_channels//2, add_self_loops=False)\n",
        "        self.lin = Linear(-1, num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        # x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(self.conv2(x, edge_index), p=0.6, training=self.training)\n",
        "        x = F.log_softmax(self.lin(x), dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "UH78leeA96AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 50"
      ],
      "metadata": {
        "id": "YF8Bg6NaGoVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def init_params(model):\n",
        "  batch = next(iter(train_loader))\n",
        "  batch = batch.to(device)\n",
        "  model(batch.x_dict, batch.edge_index_dict)\n",
        "\n",
        "def train(model, optimizer):\n",
        "  model.train()\n",
        "\n",
        "  total_examples = total_loss = 0\n",
        "  for batch in tqdm(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    batch = batch.to(device)\n",
        "    batch_size = batch['tweet'].batch_size\n",
        "    out = model(batch.x_dict, batch.edge_index_dict)['tweet'][:batch_size]\n",
        "    loss = F.nll_loss(out, batch['tweet'].y[:batch_size].argmax(dim=-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_examples += batch_size\n",
        "    total_loss += float(loss) * batch_size\n",
        "\n",
        "  return total_loss / total_examples\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, loader):\n",
        "  model.eval()\n",
        "  preds, targets = [], []\n",
        "  for batch in tqdm(loader):\n",
        "    batch = batch.to(device)\n",
        "    batch_size = batch['tweet'].batch_size\n",
        "    pred = model(batch.x_dict, batch.edge_index_dict)['tweet'][:batch_size].argmax(dim=-1)\n",
        "    target = batch['tweet'].y[:batch_size].argmax(dim=-1)\n",
        "    preds.append(pred)\n",
        "    targets.append(target)\n",
        "  \n",
        "  preds = torch.concat(preds).cpu().numpy()\n",
        "  targets = torch.concat(targets).cpu().numpy()\n",
        "\n",
        "  report = classification_report(targets, preds, target_names=[topic_labels[idx2topic[k]] for k in np.arange(num_classes)], digits=4, output_dict=True)\n",
        "  matrix = confusion_matrix(targets, preds)\n",
        "  acc = matrix.diagonal()/matrix.sum(axis=1)\n",
        "  acc = {topic_labels[idx2topic[k]]: acc[k] for k in np.arange(num_classes)}\n",
        "  del report['weighted avg']\n",
        "  del report['macro avg']\n",
        "  del report['accuracy']\n",
        "  for label, stat in report.items(): \n",
        "      stat['accuracy'] = acc[label]\n",
        "      report[label] = stat\n",
        "  return report\n",
        "\n",
        "@torch.no_grad()\n",
        "def top_k_acc(model, loader, n):\n",
        "  model.eval()\n",
        "  total_examples = total_acc = 0\n",
        "  accuracy = Accuracy(top_k=n).to(device)\n",
        "  for batch in tqdm(loader):\n",
        "    batch = batch.to(device)\n",
        "    batch_size = batch['tweet'].batch_size\n",
        "    out = model(batch.x_dict, batch.edge_index_dict)['tweet'][:batch_size]\n",
        "    target = batch['tweet'].y[:batch_size].argmax(dim=-1)\n",
        "    acc = accuracy(out, target)\n",
        "    total_examples += batch_size\n",
        "    total_acc += acc * batch_size\n",
        "  \n",
        "  return total_acc / total_examples\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict(model, loader, n):\n",
        "  model.eval()\n",
        "  preds = []\n",
        "  targets = []\n",
        "  tweet_indices = []\n",
        "  for batch in tqdm(loader):\n",
        "    batch = batch.to(device)\n",
        "    batch_size = batch['tweet'].batch_size\n",
        "    tweet_idx = batch['tweet'].idx[:batch_size]\n",
        "\n",
        "    out = model(batch.x_dict, batch.edge_index_dict)['tweet'][:batch_size]\n",
        "    target = batch['tweet'].y[:batch_size]\n",
        "\n",
        "    preds.append(out)\n",
        "    targets.append(target)\n",
        "    tweet_indices.append(tweet_idx)\n",
        "  \n",
        "  preds = torch.cat(preds, dim=0)\n",
        "  targets = torch.cat(targets, dim=0)\n",
        "  tweet_indices = torch.cat(tweet_indices)\n",
        "  \n",
        "\n",
        "  preds = torch.topk(preds, n, dim=1).indices\n",
        "  targets = torch.topk(targets, 1, dim=1).indices\n",
        "  pred_labels = [[topic_labels[idx2topic[idx.item()]] for idx in pred] for pred in preds]\n",
        "  target_labels = [[topic_labels[idx2topic[idx.item()]] for idx in target] for target in targets]\n",
        "\n",
        "  tweet_ids = [idx2tweetId[int(idx)] for idx in tweet_indices]\n",
        "\n",
        "  return pred_labels, target_labels, tweet_ids"
      ],
      "metadata": {
        "id": "CiMIPVaK_lug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter('KG embedding/runs/node classification/09-12-13:50')"
      ],
      "metadata": {
        "id": "vZL3xjWoNHKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def train_gnn(config):\n",
        "  acc = []\n",
        "  model = to_hetero_with_bases(GNN(hidden_channels=64, num_classes=num_classes), data.metadata(), num_bases=2).to(device)\n",
        "  init_params(model)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "  for epoch in range(1, config[\"epoch\"]+1):\n",
        "    loss = train(model, optimizer)\n",
        "    train_acc = top_k_acc(model, train_loader, 1)\n",
        "    val_acc = top_k_acc(model, val_loader, 1)\n",
        "    top_3_acc = top_k_acc(model, val_loader, 3)\n",
        "    top_5_acc = top_k_acc(model, val_loader, 5)\n",
        "    writer.add_scalar('training loss', loss, epoch)\n",
        "    writer.add_scalar('training accuracy', train_acc, epoch)\n",
        "    writer.add_scalar('validation accuracy', val_acc, epoch)\n",
        "    writer.add_scalar('top 3 accuracy', top_3_acc, epoch)\n",
        "    writer.add_scalar('top 5 accuracy', top_5_acc, epoch)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Top 3 Acc: {top_3_acc:.4f}, Top 5 Acc: {top_5_acc:.4f}\")\n",
        "    acc.append(val_acc)\n",
        "    \n",
        "  return acc"
      ],
      "metadata": {
        "id": "fti3Mx4-FOzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accs = []\n",
        "for epoch in [10, 20]:\n",
        "  accs_epoch = []\n",
        "  for lr in np.linspace(0.001, 0.01, 8):\n",
        "    print(f\"INFO: current hyperparameters: lr={lr}, epoch={epoch}\")\n",
        "    acc = train_gnn({\"lr\": lr, \"epoch\": epoch})\n",
        "    accs_epoch.append(torch.stack(acc).cpu().numpy())\n",
        "    print(f\"INFO: the average accuracy: {torch.mean(torch.stack(acc).cpu())}\")\n",
        "    print()\n",
        "  accs.append(accs_epoch)\n"
      ],
      "metadata": {
        "id": "iX8TL_oLUyB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 8))\n",
        "for j in range(2):\n",
        "  plt.subplot(1, 2, j+1)\n",
        "  for i in range(8):\n",
        "    plt.plot([x for x in accs[j][i]], label=np.linspace(0.001, 0.01, 8)[i], linestyle='-.')\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "eaG23UI7ul7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter('KG embedding/runs/node classification/09-12-15:02')\n",
        "model = to_hetero_with_bases(GNN(hidden_channels=64, num_classes=num_classes), data.metadata(), num_bases=2).to(device)\n",
        "init_params(model)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "accs = []\n",
        "top_3_accs = []\n",
        "top_5_accs = []\n",
        "for epoch in range(1, 20):\n",
        "  loss = train(model, optimizer)\n",
        "  train_acc = top_k_acc(model, train_loader, 1)\n",
        "  val_acc = top_k_acc(model, val_loader, 1)\n",
        "  top_3_acc = top_k_acc(model, val_loader, 3)\n",
        "  top_5_acc = top_k_acc(model, val_loader, 5)\n",
        "  accs.append(val_acc.item())\n",
        "  top_3_accs.append(top_3_acc.item())\n",
        "  top_5_accs.append(top_5_acc.item())\n",
        "  writer.add_scalar('training loss', loss, epoch)\n",
        "  writer.add_scalar('training accuracy', train_acc, epoch)\n",
        "  writer.add_scalar('validation accuracy', val_acc, epoch)\n",
        "  writer.add_scalar('top 3 accuracy', top_3_acc, epoch)\n",
        "  writer.add_scalar('top 5 accuracy', top_5_acc, epoch)\n",
        "\n",
        "  print(f\"Epoch {epoch:02d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Top 3 Acc: {top_3_acc:.4f}, Top 5 Acc: {top_5_acc:.4f}\")"
      ],
      "metadata": {
        "id": "LuwmFvMzwD-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(top_k_acc(model, test_loader, 1))\n",
        "print(top_k_acc(model, test_loader, 3))\n",
        "print(top_k_acc(model, test_loader, 5))"
      ],
      "metadata": {
        "id": "AyEPZSNEXqhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reports = []\n",
        "for i in range(10):\n",
        "  report = test(model, test_loader)\n",
        "  reports.append(report)\n",
        "\n",
        "avg_report = {}\n",
        "for topic in reports[0].keys():\n",
        "  avg_report[topic] = {'accuracy': [], 'f1-score': [], 'precision': [], 'recall': [], 'support': []}\n",
        "  for report in reports:\n",
        "    for metric in avg_report[topic].keys():\n",
        "      avg_report[topic][metric].append(report[topic][metric])\n",
        "\n",
        "for topic in avg_report:\n",
        "  for metric in ['accuracy', 'f1-score', 'precision', 'recall', 'support']:\n",
        "    avg_report[topic][metric] = sum(avg_report[topic][metric])/10\n",
        "\n",
        "pd.DataFrame.from_dict(avg_report)"
      ],
      "metadata": {
        "id": "XrVy4A3c3Mpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_acc = [metric['accuracy'] for _, metric in avg_report.items()]\n",
        "avg_f1 = [metric['f1-score'] for _, metric in avg_report.items()]\n",
        "barwidth = 0.4\n",
        "br = np.arange(1, len(avg_acc)+1)\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.bar(br, avg_acc, width=barwidth, label='Accuracy')\n",
        "br2 = [x + barwidth for x in br]\n",
        "plt.bar(br2, avg_f1, width=barwidth, label='F1-score')\n",
        "plt.xticks(br, rotation=45)\n",
        "plt.hlines(y=0.7, xmin=0.5, xmax=num_classes+1.5, color='r', ls='--')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "E4Fgi-JKFwQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accurate_topics = []\n",
        "for topic, metrics in avg_report.items():\n",
        "  if (avg_report[topic]['f1-score'] >= 0.7):\n",
        "      accurate_topics.append(topic)\n",
        "\n",
        "accurate_topics"
      ],
      "metadata": {
        "id": "Xp3efwCtEgRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"KG embedding/ndoe_class_50_model_weights_9_12.pth\")"
      ],
      "metadata": {
        "id": "XdjJY6Go-vFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer.flush()\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "zCEDe_mBN0qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip3 install tensorboard\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "wTKOTmAHN5iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=/content/drive/MyDrive/Knowledge\\ Graphs\\ 2022/KG\\ embedding/runs/node\\ classification/09-12-15:02"
      ],
      "metadata": {
        "id": "BHy7h7VVN96c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds, targets, tweet_ids = predict(model, test_loader, 3)"
      ],
      "metadata": {
        "id": "liejGrD5fahV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(len(tweet_ids)):\n",
        "  tweet = all_tweets_df[all_tweets_df.index == tweet_ids[idx]]\n",
        "  if (tweet['topic_probability'].values[0] >= 0.5) and (targets[idx] == [topic_labels[0]]):\n",
        "    print(f\"tweet: {tweet['text'].values[0]}\")\n",
        "    print(f\"prediction: {preds[idx]}\")\n",
        "    print(f\"ground truth: {targets[idx]}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "erEAfjv1k97d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('bot detection/potential_bot_users.list', 'r') as f:\n",
        "  bot_user_list = [int(x) for x in f.read().split('\\n')[:-1]]\n",
        "\n",
        "bot_tweets_id_list = all_tweets_df[all_tweets_df['user_id'].isin(bot_user_list)].index.tolist()\n",
        "all_tweets_df = all_tweets_df[~all_tweets_df.index.isin(bot_tweets_id_list)]"
      ],
      "metadata": {
        "id": "jaDPavTGJQxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "4ROH1Xdxtbzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.load_state_dict(torch.load(\"KG embedding/ndoe_class_50_model_weights_9_12.pth\"))\n",
        "# model.eval()"
      ],
      "metadata": {
        "id": "wZb27IoFYj2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accurate_topics = ['the vaccine|get vaccinated|to get',\n",
        "#  'yes yes|yes yes yes|yes he',\n",
        "#  'titus ray|great idea|ray thrillers',\n",
        "#  'the virus|to china|the chinese',\n",
        "#  'wear mask|to wear|the cdc',\n",
        "#  'stories via|press is out|press is',\n",
        "#  'fake news|just completed minutes|meditation with',\n",
        "#  'an idiot|she is|who cares',\n",
        "#  'just posted|just posted photo|posted photo']"
      ],
      "metadata": {
        "id": "W5J9DLbuk9u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"KG embedding/idx2tweetId_prediction.pickle\", 'rb') as f:\n",
        "  idx2tweetId = pickle.load(f)\n",
        "\n",
        "with open(\"KG embedding/idx2userId_prediction.pickle\", 'rb') as f:\n",
        "  idx2userId = pickle.load(f)"
      ],
      "metadata": {
        "id": "s3aTp_DPsxLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"KG embedding/dataset/data_dict_node_classification_50_topics_prediction.pickle\", \"rb\") as f:\n",
        "  data_dict = pickle.load(f)\n",
        "data = HeteroData(data_dict)\n",
        "data"
      ],
      "metadata": {
        "id": "29QZMemdtkKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['tweet']"
      ],
      "metadata": {
        "id": "TTBW3oa8tpdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "transform = T.Compose([\n",
        "    T.AddSelfLoops(),\n",
        "    T.ToUndirected(),\n",
        "    T.ToDevice(device)\n",
        "])\n",
        "\n",
        "data = transform(data)\n",
        "\n",
        "data[\"tweet\"].test_mask = torch.ones(data[\"tweet\"].idx.shape[0]).bool().to(device)\n",
        "data"
      ],
      "metadata": {
        "id": "FWBnr6ults-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_data_loader = HGTLoader(data, num_samples=[1024]*4, shuffle=True, batch_size=1024, input_nodes=('tweet', data['tweet'].test_mask), num_workers=2)\n",
        "sampled_data = next(iter(predict_data_loader))\n",
        "print(sampled_data)"
      ],
      "metadata": {
        "id": "Yb-M35fMty77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds, targets, tweet_ids = predict(model, predict_data_loader, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUm91-nfvasl",
        "outputId": "8a84d460-186c-4125-ac43-dac7c73d1111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 902/902 [02:22<00:00,  6.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_no_topics = all_tweets_df[all_tweets_df['topic'] == -1]\n",
        "tweets_no_topics"
      ],
      "metadata": {
        "id": "60R78iIPGNXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recovered_tweets = {}\n",
        "for idx in tqdm(range(len(tweet_ids)), total=len(tweet_ids)):\n",
        "  tweet = tweets_no_topics[tweets_no_topics.index == tweet_ids[idx]]\n",
        "  if (len(tweet) > 0) and (preds[idx][0] in accurate_topics):\n",
        "    recovered_tweets[tweet_ids[idx]] = topic_labels.index(preds[idx][0])"
      ],
      "metadata": {
        "id": "5y34rUk4Fzex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(recovered_tweets.values())"
      ],
      "metadata": {
        "id": "OamRJBjVKfLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_labels = ['the election|voter fraud|to vote',\n",
        " 'wear mask|to wear|wearing mask',\n",
        " 'yes yes|yes yes yes|yes he',\n",
        " 'yasss its|yasss its time|its time for',\n",
        " 'the truth|truth is|thank you',\n",
        " 'the follow|for the follow|biz get paid',\n",
        " 'to win|gun control|just entered']\n",
        "for i, id in enumerate([0, 13, 24, 31, 39, 44, 48]):\n",
        "  print(f\"Topic with keywords: {topic_labels[i]}\")\n",
        "  print(f\"before completion: {len(all_tweets_df[all_tweets_df['topic'] == id])}\")\n",
        "  print(f\"after completion: {len(all_tweets_df_recovered_topics[all_tweets_df_recovered_topics['topic'] == id])}\")"
      ],
      "metadata": {
        "id": "ucrLGPnu4Cz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_tweets_df[all_tweets_df['topic'] != -1])/len(all_tweets_df))\n",
        "print(len(all_tweets_df_recovered_topics[all_tweets_df_recovered_topics['topic'] != -1])/len(all_tweets_df))\n",
        "print(len(all_tweets_df_recovered_topics[all_tweets_df_recovered_topics['topic'] != -1]) - len(all_tweets_df[all_tweets_df['topic'] != -1]))"
      ],
      "metadata": {
        "id": "Ra-HSn_74PHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(recovered_tweets.values())"
      ],
      "metadata": {
        "id": "UjYprO9fpiJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for id, row in tqdm(all_tweets_df.iterrows(), total=len(all_tweets_df)):\n",
        "  if id in recovered_tweets:\n",
        "    all_tweets_df.at[id, 'topic'] = recovered_tweets[id]\n",
        "    "
      ],
      "metadata": {
        "id": "pquqJO7oKrxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tweets_df[all_tweets_df['topic'] == -1]"
      ],
      "metadata": {
        "id": "qWb6lqpUSa7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tweets_df = all_tweets_df.drop(\"topic_probability\", axis=1)\n",
        "all_tweets_df.to_csv(\"data/tweets_w_recovered_50_topics.csv\")"
      ],
      "metadata": {
        "id": "K2lIgA3dSfw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_tweets = []\n",
        "for idx in tqdm(range(len(tweet_ids)), total=len(tweet_ids)):\n",
        "  tweet = all_tweets_df[all_tweets_df.index == tweet_ids[idx]]\n",
        "  if (topic_labels[0] in preds[idx]):\n",
        "    # print(f\"tweet: {tweet['text'].values[0]}\")\n",
        "    # print(f\"prediction: {preds[idx]}\")\n",
        "    # print()\n",
        "    selected_tweets.append(tweet_ids[idx])\n",
        "\n",
        "print(len(selected_tweets))"
      ],
      "metadata": {
        "id": "RGLrnUwRvh_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_df = all_tweets_df[all_tweets_df.index.isin(selected_tweets)]\n",
        "selected_df = selected_df.fillna('')"
      ],
      "metadata": {
        "id": "MXfy9V7caqoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tweets_df_recovered_topics = pd.read_csv(\"data/tweets_w_recovered_50_topics.csv\", index_col=0)\n",
        "all_tweets_df_recovered_topics"
      ],
      "metadata": {
        "id": "g451XuOrWEtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(np.arange(50))\n",
        "labels.insert(0, -1)\n",
        "counts = []\n",
        "topic_ids = list(set(all_tweets_df['topic']))\n",
        "topic_ids = [topic_ids[-1]] + topic_ids[:-1]\n",
        "for topic in topic_ids:\n",
        "  counts.append(len(all_tweets_df[all_tweets_df['topic'] == topic]))\n",
        "\n",
        "plt.rcParams['font.size'] = '30'\n",
        "fig1, ax1 = plt.subplots(figsize=(10, 10))\n",
        "labels = ['topic -1', 'topic 1 ~ 50']\n",
        "counts = [counts[0], sum(counts[1:])]\n",
        "ax1.pie(counts, labels=labels, autopct='%1.1f%%',\n",
        "        shadow=False, startangle=90)\n",
        "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IMJj8cFNr8g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_total_topics = len(all_tweets_df_recovered_topics[all_tweets_df_recovered_topics['topic'] != -1])\n",
        "n_original_topics = len(all_tweets_df[all_tweets_df['topic'] != -1])\n",
        "n_topics = len(all_tweets_df)"
      ],
      "metadata": {
        "id": "NP_qWdugbkU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig1, ax1 = plt.subplots(figsize=(10, 10))\n",
        "new_counts = [n_topics-n_total_topics, n_original_topics, n_total_topics-n_original_topics]\n",
        "new_labels = ['topic -1', 'original', 'completed']\n",
        "ax1.pie(new_counts, labels=new_labels, autopct='%1.1f%%',\n",
        "        shadow=False, startangle=90)\n",
        "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Glc4lTnMsLEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tweets_df = pd.read_csv('data/all_tweets_50_topics.csv', index_col=0)\n",
        "all_tweets_df"
      ],
      "metadata": {
        "id": "5Xz1MwiYWpC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for idx, row in all_tweets_df.iterrows():\n",
        "  if count == 10:\n",
        "    break\n",
        "  if all_tweets_df.at[idx, 'topic'] == -1 and all_tweets_df_recovered_topics.at[idx, 'topic'] == 0:\n",
        "    print(all_tweets_df_recovered_topics.at[idx, 'text'])\n",
        "    print(topic_labels[all_tweets_df_recovered_topics.at[idx, 'topic']])\n",
        "    display(all_tweets_df_recovered_topics[all_tweets_df_recovered_topics['user_id'] == all_tweets_df_recovered_topics.at[idx, 'user_id']])\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "dQhfmsa9WOqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_recovered_topics = dict()\n",
        "for idx, row in tqdm(all_tweets_df_recovered_topics.iterrows(), total=len(all_tweets_df_recovered_topics)):\n",
        "  if all_tweets_df.at[idx, 'topic'] == -1 and all_tweets_df_recovered_topics.at[idx, 'topic'] != -1:\n",
        "    user = all_tweets_df.at[idx, 'user_id']\n",
        "    if user in user_recovered_topics:\n",
        "      user_recovered_topics[user] += 1\n",
        "    else:\n",
        "      user_recovered_topics[user] = 1"
      ],
      "metadata": {
        "id": "6-FCVYRxZ1F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### example 1"
      ],
      "metadata": {
        "id": "9YDE4RJLfcgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_user_recovered_topics = sorted(user_recovered_topics.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "with open(\"bot detection/potential_bot_users.list\", 'r') as f:\n",
        "  bot_users = [int(x) for x in f.read().split('\\n')[:-1]]\n",
        "\n",
        "sorted_user_recovered_topics = [(user, frequency) for user, frequency in sorted_user_recovered_topics if user not in bot_users]\n",
        "\n",
        "filtered_users = [(user, frequency) for user, frequency in sorted_user_recovered_topics if frequency <= 30]\n",
        "filtered_tweets = []\n",
        "for idx, row in all_tweets_df[all_tweets_df['user_id'] == filtered_users[0][0]].iterrows():\n",
        "  if (row['topic'] == -1) and (all_tweets_df_recovered_topics.at[idx, 'topic'] != -1):\n",
        "      filtered_tweets.append(idx)\n",
        "      \n",
        "test = all_tweets_df_recovered_topics[all_tweets_df_recovered_topics.index.isin(filtered_tweets)]\n",
        "test['original_topic'] = all_tweets_df[all_tweets_df.index.isin(filtered_tweets)]['topic']\n",
        "test"
      ],
      "metadata": {
        "id": "jnEM4QdeaaE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### example 2"
      ],
      "metadata": {
        "id": "6ODBTQPufiIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tweets = []\n",
        "for idx, row in all_tweets_df[all_tweets_df['user_id'] == filtered_users[1][0]].iterrows():\n",
        "  if (row['topic'] == -1) and (all_tweets_df_recovered_topics.at[idx, 'topic'] != -1):\n",
        "      filtered_tweets.append(idx)\n",
        "      \n",
        "test = all_tweets_df_recovered_topics[all_tweets_df_recovered_topics.index.isin(filtered_tweets)]\n",
        "test['original_topic'] = all_tweets_df[all_tweets_df.index.isin(filtered_tweets)]['topic']\n",
        "test"
      ],
      "metadata": {
        "id": "sZrE08AsfWS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### example 3"
      ],
      "metadata": {
        "id": "4CtjXBE89cJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filtered_users = [(user, frequency) for user, frequency in sorted_user_recovered_topics if frequency >= 30]\n",
        "filtered_tweets = []\n",
        "for idx, row in all_tweets_df[all_tweets_df['user_id'] == filtered_users[1][0]].iterrows():\n",
        "  if (row['topic'] == -1) and (all_tweets_df_recovered_topics.at[idx, 'topic'] != -1):\n",
        "      filtered_tweets.append(idx)\n",
        "      \n",
        "test = all_tweets_df_recovered_topics[all_tweets_df_recovered_topics.index.isin(filtered_tweets)]\n",
        "test['original_topic'] = all_tweets_df[all_tweets_df.index.isin(filtered_tweets)]['topic']\n",
        "test"
      ],
      "metadata": {
        "id": "-JXOZcxj9doQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_tweets_df[all_tweets_df['topic'] == 0]))\n",
        "print(len(all_tweets_df_recovered_topics[all_tweets_df_recovered_topics['topic'] == 0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cdUdObZXrZL",
        "outputId": "e891c7c6-2543-4af2-a75e-36d402aebb78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10559\n",
            "57855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "topic_0_tweets = all_tweets_df_recovered_topics[all_tweets_df_recovered_topics['topic'] == 0]\n",
        "topic_0_tweets = topic_0_tweets.fillna('')\n",
        "topic_0_tweets['cleaned_text'] = topic_0_tweets.apply(lambda row: \" \".join(re.sub(\"[^a-zA-Z]+\", \" \", row.cleaned_text).split()), 1)\n",
        "topic_0_tweets = topic_0_tweets.drop_duplicates(subset='cleaned_text')\n",
        "docs = topic_0_tweets['cleaned_text'].tolist()\n",
        "print(len(docs))"
      ],
      "metadata": {
        "id": "8vXEWg9tdRH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model = BERTopic(language='multilingual', n_gram_range=(2, 3), min_topic_size=50, nr_topics=20, calculate_probabilities=True)\n",
        "topics, probs = topic_model.fit_transform(docs)"
      ],
      "metadata": {
        "id": "Gf_u1rE1ZQst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.set_topic_labels(topic_model.generate_topic_labels(nr_words=3, topic_prefix=False, word_length=None, separator='|'))\n",
        "topic_model.visualize_hierarchy(custom_labels=True, top_n_topics=20)"
      ],
      "metadata": {
        "id": "gTkmSFuUZ7JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.visualize_barchart(n_words=10, top_n_topics=20)"
      ],
      "metadata": {
        "id": "KgqHSKAZcS4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics_over_time = topic_model.topics_over_time(docs, topic_0_tweets['time'].tolist())\n",
        "topic_model.visualize_topics_over_time(topics_over_time)"
      ],
      "metadata": {
        "id": "Yf6er4Q5i1uh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}